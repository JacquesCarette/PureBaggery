\documentclass{article} % change to whatever later
\usepackage{fullpage}
\usepackage{amsmath,amsthm}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}

\theoremstyle{definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

\newcommand{\PL}{PL} % expand out later
\newcommand{\BSp}{\(\mathbf{B}\)-Species}
\newcommand{\LSp}{\(\mathbf{L}\)-Species}

\title{Structured Positions}
\author{}

\begin{document}
\maketitle
\begin{abstract}
The well-supported data-structures, aka inductive types, in functional
languages are insufficiently rich. We can do better.
\end{abstract}

The starting-point question is: how can one properly teach a \PL about
bags (aka multisets)?

Adding a single new type is rather boring though. Even though doing it
properly is difficult (most languages have rather poor abstraction facilities
so that giving a proper API that doesn't \emph{leak} is hard), it is still
to \textit{ad hoc}. The desire is to find a family of ``type constructors''
that would contain both inductive types and bags.

And even that is aiming far too low. The real problem is 
\textbf{how to teach computers about structures}. In other words, if a
human performs the act of defining a particular structure, a lot of
natural \emph{kit} should come along ``for free'' as a side-effect of
that declaration of intent. (Haskell's \texttt{Deriving} mechanism is
a reasonable analogy; of course getting an induction principle should also
be within scope).

\section{Better Structures}

In a way, we already know that this is \texit{in theory} feasible:
species, \BSp and \LSp. In practice, the theory is insufficiently
constructive nor does it provide answers for key aspects of treating
a structure so obtained as a \emph{data} structure. In particular, no
eliminator.

Another approach is to use the theory of containers. Which, unfortunately,
don't give eliminators either!

\section{Random Jumble}

Basically, self-notes so that things don't get forgotten.

\subsection{Symmetries of trees}
\label{sec:sym-trees}

Start with the not terribly useful "the symmetries of the positions of List".
Boring, as they are trivial. BUT List is tricky as it is the normal form (or
effective presentation) of the carrier of free monoids. You *could* also take
the term algebra and quotient it by the monoid equations (as a classical
mathematician might do). The resulting trees *do* have symmetries! These are
easier to see if one generalizes positions to be 2-sorted, with 1 sort for the
things that contain data, and another for the 'nil' nodes. The resulting
symmetries basically says that the 'nil' nodes cannot convey information. I
don't have an easy way to talk about associativity (yet).  

\subsection{Whence the groups?}

I'm thinking that the group elements (which we now know are equivalence
witnesses for our proof-relevant Setoids of positions) will have a double life,
and show up as generators and relations of an equational theory. Because
equivalences have reflectivity, symmetry and transitivity (and these are
coherent), this is why we get groups. But which group is guided by what other
terms we have. And, lo and behold, all 'swap's is what generates all
permutations is what generates Sn is what gives Bags which are free commutative
monoids.

The connection with Section~\ref{sec:sym-trees} should be clear.
\end{document}
